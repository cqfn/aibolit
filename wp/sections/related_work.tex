There are many definitions of a defect.  
\citet{5989519} says that defect is ``a fault, bug, inaccuracy or lack of expected 
functionality in a project artifact.'' 
\citet{Assurance} says that it is ``a problem 
(synonym of fault) which, if not corrected, 
could cause an application to either fail or to produce incorrect results.''

Defects and software quality are directly related. There are multiple studies 
of defect types, their impact, complexity, 
root causse and other characteristics,~\citet[e.g.][]{10.1145/69605.2085, 
10.5555/256664.256773, 10.1145/390016.808455, Glass1981PersistentSE, 
10.1145/1353535.1346323, 10.1007/s10664-013-9258-8, catolino2019bugs}.
There are a few common preventive ways to deal with defects, like 
static code analyzers, testing software, or peer code review. 

Static code analyzer 
is a tool that helps find defects before a program is executed. 
Such an analyzer inspects various program representations, for example 
Abstract Syntax Tree (AST), Control Flow Graphs (CFG), or
Program Dependency Graph (PDG), 
and search for handcrafted defect patterns. 
These tools are popular among developers and are often embedded into
Integrated Development Environments (IDE) such as IntelliJ IDEA or NetBeans. 
There are more than 40 static analyzers currently on the market, including
very famouns open source projects, such as
PMD, Rubocop, PHPCS, Sparse, CLion, cpplint, FindSecBugs, ESLint, and Checkstyle.
There are also many commercial tools, like 
IBM Security AppScan, PVS-Studio, SonarQube, and Parasoft.
Software companies like Google and Facebook have their own open source
static analyzers: Error Prone~\citep{10.1109/SCAM.2012.28} and 
Infer~\citep{10.1007/978-3-319-17524-9_1} respectively. 
Static code analyzer may vary in supported languages, 
supported defect types, and their integration workflow.

Usually static code analyzers are rule-based. 
In order to detect a new kind of defect their developers have to
design a new pattern. To address this extensibility problem 
there were attempts to learn pattern
from data, as explained by~\citet{bielik2016learning, wang2019learning}.

Recent empirical study by~\citet{10.1145/3238147.3238213} demonstrates that 
state-of-the-art code analyzers miss more than 90\% of defects. Most of those missed 
defects are inconsistencies with the specification or programmer's intent. 
In order to catch such defects it is necessary to reason about 
possible behavior depending on the input data, 
which is difficult or impossible for the rule-based approach. 
Such defects are known as \emph{semantic} defects. 
It has been demonstrated by~\citet{10.1007/s10664-013-9258-8} 
that semantic defects are the dominant root cause for the majoirity of security issues, 
when attacker may get unauthorized access to some resources.

Another issue of most static analyzers is their high 
percent of ``false-positives,'' when they find a defect, which
in reality is not a defect. The amount of these false signals grows 
when the size and complexity of the project increases. 
This leads to developers loosing trust to the tool and stop
using it. 

The efficiency of static analyzers is yet another problem. It was
empirically shown by~\citet{10.1145/3188720} that 
a better performance metric for a static analyzer 
is the amount of fixed, rather than found defects. 
Static analyzers must provide the right information 
at the right time doing everything possible to not annoy 
software developers. 

Usually, static code analyzers use fixed in time code versions as their
input. However, one can also use the history of code changes and 
the information from the Issue Tracking System (ITS) 
to enhance the quality of prediction, as done by~\citet{Gupta2018IntelligentCR, kapur2018estimating}.

There are studies trying to use ML in order to detect defects. 
For example, \citet{Dam2018ADT} first trained vector representations of 
an AST in an unsupervised manner and then used it as a feature vector 
to train the binary classifier. 
\citet{kapur2018estimating} 
combined the information extracted from the code programming style and ITS 
and built a predictor to estimate the defectiveness of an input source code 
file. Using an idea that the names of identifiers (variables, classes, functions) 
convey useful information, which might be used to understand programmer's 
intent,
\citet{Pradel2018DeepBugsAL} proposed a method that first learned 
vector representation of identifiers 
and obtained a fixed length vector for a code snippet to train a binary classifier 
with feed-forward neural network. 
\citet{vasic2019neural} used pointer-network to do joint prediction of 
both the location and the possible fix for variable misuse bugs. 
\citet{briem2019using} used attention-based neural network  to model binary 
classifier to detect off-by-one defects.
